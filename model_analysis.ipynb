{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "from scipy.linalg import sqrtm\n",
    "from torchvision.models import inception_v3\n",
    "import torchvision.transforms.functional as TF\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute Fr√©chet Inception Distance (FID)\n",
    "def calculate_fid(real_images, generated_images, device='mps'):\n",
    "    real_images = real_images.detach().cpu().numpy()\n",
    "    generated_images = generated_images.detach().cpu().numpy()\n",
    "\n",
    "    # Preprocess images\n",
    "    real_images = np.transpose(real_images, (0, 2, 3, 1))  # Change from NCHW to NHWC\n",
    "    generated_images = np.transpose(generated_images, (0, 2, 3, 1))\n",
    "\n",
    "    # Load pre-trained Inception v3 model\n",
    "    inception_model = inception_v3(pretrained=True, transform_input=False).to(device)\n",
    "    inception_model.eval()\n",
    "\n",
    "    # Compute activations for real and generated images\n",
    "    with torch.no_grad():\n",
    "        real_activations = inception_model(torch.tensor(real_images).to(device)).detach().cpu().numpy()\n",
    "        generated_activations = inception_model(torch.tensor(generated_images).to(device)).detach().cpu().numpy()\n",
    "\n",
    "    # Compute mean and covariance of activations\n",
    "    mu_real = np.mean(real_activations, axis=0)\n",
    "    mu_generated = np.mean(generated_activations, axis=0)\n",
    "    cov_real = np.cov(real_activations, rowvar=False)\n",
    "    cov_generated = np.cov(generated_activations, rowvar=False)\n",
    "\n",
    "    # Compute FID\n",
    "    fid = np.sum((mu_real - mu_generated) ** 2) + np.trace(cov_real + cov_generated - 2 * sqrtm(np.dot(cov_real, cov_generated)))\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # Ensure images are moved to CPU and converted for metric calculation\n",
    "    # right now we are only working with single images\n",
    "    real_image_np = real_A.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "    fake_image_np = fake_B.cpu().numpy().transpose(0, 2, 3, 1) \n",
    "    real_image_np = np.squeeze(real_image_np, axis = 0) # get rid of first channel because it is just batch size 1\n",
    "    fake_image_np = np.squeeze(fake_image_np, axis = 0)\n",
    "                # Clipping pixel values to ensure they are within [0, 1]\n",
    "    print(\"Real image: \", real_image_np)\n",
    "    print(\"Fake image: \", fake_image_np)\n",
    "    real_image_np = np.clip(real_image_np, 0, 1)\n",
    "    fake_image_np = np.clip(fake_image_np, 0, 1)\n",
    "\n",
    "    print(real_image_np.shape, fake_image_np.shape)\n",
    "    # print(\"Real image: \", real_image_np)\n",
    "    # print(\"Fake image: \", fake_image_np)\n",
    "\n",
    "    image_ssim = ssim(real_image_np, fake_image_np, multichannel=True, channel_axis = 2, dtype = np.float32, data_range =[0,1])\n",
    "    image_psnr = psnr(real_image_np, fake_image_np)\n",
    "\n",
    "    # Append scores\n",
    "    ssim_scores.append(image_ssim)\n",
    "    psnr_scores.append(image_psnr)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
